import binascii
import glob
import multiprocessing
import os
import platform
import scapy.all as scapy
import shlex
import socket
import subprocess
import sys
import time

use_experimental_sched = int($BESS_EXP_SCHED!'1')
#use_experimental_sched = int($BESS_EXP_SCHED!'0')

TX_QUEUE_COUNT = multiprocessing.cpu_count()
RX_QUEUE_COUNT = 16
TX_QSIZE = 256
RX_QSIZE = 2048
DUMP_IVAL = 0.00001
VPORT = True

# DEBUGGING
#bess.set_debug(True)

# Helpers
def aton(ip):
    return socket.inet_aton(ip)
# CloudLab experiment platform specific code:
def node2id(node):
    node2id_dict = {
        'pinter': 1,
        'jarry': 2,
        'node-1.loomtest2.opennf-pg0.clemson.cloudlab.us': 1,
        'node-0.loomtest2.opennf-pg0.clemson.cloudlab.us': 2,
    }
    return node2id_dict[node]
node_name = platform.node()
node_id = node2id(node_name)
def config_rfs(iface):
    rxqs = glob.glob('/sys/class/net/%s/queues/rx-*' % iface)
    entries = 65536
    entries_per_rxq = entries / len(rxqs)
    cmd = 'echo %d | sudo tee /proc/sys/net/core/rps_sock_flow_entries > /dev/null' % \
        entries
    subprocess.check_call(cmd, shell=True)
    for rxq in rxqs:
        cmd = 'echo %d | sudo tee /%s/rps_flow_cnt > /dev/null' % (entries_per_rxq, rxq)
        subprocess.check_call(cmd, shell=True)
def start_ping_proc(ip):
    ping_cmd = 'sudo ping -i 0.001 -c 20 %s' % ip
    proc = subprocess.Popen(ping_cmd, shell=True,
        stderr=subprocess.STDOUT, stdout=subprocess.PIPE)
    return proc
def make_tcpdump_fifo(fifo):
    try:
        os.remove(fifo)
    except:
        pass
    os.mkfifo(fifo, 0o600)
    fd = os.open(fifo, os.O_RDWR)
    return fifo

class VhostConf(object):
    def __init__(self, *initial_data, **kwargs):
        for dictionary in initial_data:
            for key in dictionary:
                setattr(self, key, dictionary[key])
        for key in kwargs:
            setattr(self, key, kwargs[key])
def gen_vhost_conf(i):
    vhost_conf_dict = {
        'name': 'loom%d' % i,
        'addr': '10.10.10%d.%d' % (i, node_id),
        'mac': '00:8c:fa:00:A{}:{:02x}'.format(i, node_id),
        'netns': 'loom_test%d' % i,
        'vlan': '10%d' % i,
    }
    vhost_conf = VhostConf(vhost_conf_dict)
    vhost_conf.addr_prefix = vhost_conf.addr + '/24'
    return vhost_conf

def config_virtio_user(vhost_conf):
    v = PMDPort(name=vhost_conf.name, vdev=vhost_conf.vdev_str, num_inc_q=TX_QUEUE_COUNT,
        num_out_q=RX_QUEUE_COUNT)
    config_rfs(vhost_conf.name)
    #TODO: network namespaces if needed
    ip_cmd_prefix = ''
    #ip_cmd_prefix = 'sudo ip netns exec %s ' % vhost_conf.netns
    #subprocess.check_call('ip link set %s netns %s' % (vhost_conf.name,
    #    vhost_conf.netns), shell=True)
    subprocess.check_call('%s ip addr add %s/24 dev %s' % (ip_cmd_prefix,
        vhost_conf.addr_prefix, vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set %s address %s' % (ip_cmd_prefix,
        vhost_conf.name, vhost_conf.mac), shell=True)
    subprocess.check_call('%s ip link set dev %s up' % (ip_cmd_prefix,
        vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set dev %s promisc on' % (ip_cmd_prefix,
        vhost_conf.name), shell=True)
    #subprocess.check_call('%s ethtool -K %s tso off' % (ip_cmd_prefix,
    #    vhost_conf.name), shell=True)
    #print("WARNING! Disabling TSO for VIRTIO-USER!")
    return v

def config_vport(vhost_conf):
    v = VPort(ifname=vhost_conf.name, ip_addrs=[vhost_conf.addr_prefix],
        num_inc_q=TX_QUEUE_COUNT, num_out_q=RX_QUEUE_COUNT)
    config_rfs(vhost_conf.name)
    ip_cmd_prefix = ''
    #ip_cmd_prefix = 'sudo ip netns exec %s ' % vhost_conf.netns
    subprocess.check_call('%s ip link set dev %s down' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set dev %s promisc on' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set %s address %s' % \
        (ip_cmd_prefix, vhost_conf.name, vhost_conf.mac), shell=True)
    subprocess.check_call('%s ip link set dev %s up' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    return v

# Reset everything at the start
#XXX: Note: I doubt both of these are necessary or are even considered
# "correct"
bess.reset_all()
#bess.resume_all()
bess.pause_all()

# Try out using different workers for inc and out
#XXX: Trying out because weighted fairness is causing problems.
#bess.add_worker(0, 0, scheduler='experimental')
#bess.add_worker(1, 28, scheduler='experimental')
bess.add_worker(0, 0)
bess.add_worker(1, 28, scheduler='experimental')
#bess.add_worker(1, 28)

bess.pause_all()

# Configure the scheduler
bess.add_tc('tenant_inc_rr',
            wid=0,
            policy='round_robin')
bess.add_tc('tenant_out_rl',
            wid=1,
            policy='rate_limit',
            resource='bit',
            limit={'bit': int(10e9)})
bess.add_tc('tenant_out_pri',
            parent='tenant_out_rl',
            policy='priority')
bess.add_tc('t1_out_rr',
            parent='tenant_out_pri',
            policy='round_robin',
            priority=2)
bess.add_tc('t2_out_rr',
            parent='tenant_out_pri',
            policy='round_robin',
            priority=1)

# Get config for each vhost
v1_vhost_conf = gen_vhost_conf(1)
v2_vhost_conf = gen_vhost_conf(2)

# Configure network namespaces
#subprocess.call('sudo ip -all netns del', shell=True)
#for netns in [v1_vhost_conf.netns, v2_vhost_conf.netns]:
#    subprocess.check_call('sudo ip netns add %s' % netns, shell=True)

# Delete then add the network namespaces
subprocess.call('sudo ip -all netns del', shell=True)
#for netns in [v1_vhost_conf.netns, v2_vhost_conf.netns]:
#    subprocess.check_call('sudo ip netns add %s' % netns, shell=True)

# Create a vhost as an interface on the host for each tenant
if VPORT:
    v1 = config_vport(v1_vhost_conf)
    v2 = config_vport(v2_vhost_conf)
else:
    v1 = config_virtio_user(v1_vhost_conf)
    v2 = config_virtio_user(v2_vhost_conf)

# Create a PMD port (physical) with q-txq and 1-rxq
## Only use 1-rxq because the 82599 with DPDK only does 16 RSS?
p = PMDPort(port_id=0, num_inc_q=RX_QUEUE_COUNT, num_out_q=1,
    size_inc_q=RX_QSIZE, size_out_q=TX_QSIZE)

# Merge all incoming traffic from the vport into a single PMD output port/queue
merge::Merge() -> IPChecksum() -> L4Checksum() ->  p_out::PortOut(port=p.name)
v1_inc::PortInc(port=v1.name) -> merge
v2_inc::PortInc(port=v2.name) -> merge

# Configure the scheduler for traffic outgoing the physical port
for i in range(TX_QUEUE_COUNT):
    v1_inc.attach_task(parent='t1_out_rr', module_taskid=i)
    v2_inc.attach_task(parent='t2_out_rr', module_taskid=i)


# Connect queues instead of ports
for i in range(RX_QUEUE_COUNT):
    # Current solution: use L2 forwarding and replicate broadcast traffic to
    # both interfaces.  In other words, implement our own L2 switch.
    l2fwd = L2Forward()
    q_inc = QueueInc(port=p.name, qid=i)
    q_inc -> IPChecksum() -> L4Checksum() -> l2fwd
    #hashlb:i -> l2fwd
    l2_entries = [{'addr': 'ff:ff:ff:ff:ff:ff', 'gate': 0},
        {'addr': v1_vhost_conf.mac, 'gate': 1},
        {'addr': v2_vhost_conf.mac, 'gate': 2},
    ]
    l2fwd.add(entries=l2_entries)
    l2fwd.set_default_gate(gate=0)
    v1out_merge = Merge()
    v1out_merge -> QueueOut(port=v1.name, qid=i)
    v2out_merge = Merge()
    v2out_merge -> QueueOut(port=v2.name, qid=i)
    l2fwd:1 -> v1out_merge
    l2fwd:2 -> v2out_merge
    bcast = Replicate(gates=[1, 2])
    l2fwd:0 -> bcast
    bcast:1 -> v1out_merge
    bcast:2 -> v2out_merge

    # Configure the scheduler
    q_inc.attach_task(parent='tenant_inc_rr')

    # DEBUG
    #fifo = make_tcpdump_fifo('/tmp/vport_q_inc_%d.pcap' % i)
    #bess.tcpdump(True, q_inc.name, fifo=fifo)

bess.resume_all()

# DEBUG
print('Two ports now share one PMD: {} <-> {} and {} <-> {}'.format(v1, p, v2, p))
