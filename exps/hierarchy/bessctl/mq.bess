import binascii
import glob
import multiprocessing
import os
import platform
import scapy.all as scapy
import shlex
import socket
import subprocess
import sys
import time

TX_QUEUE_COUNT = multiprocessing.cpu_count()
RX_QUEUE_COUNT = 16
TX_QSIZE = 128
RX_QSIZE = 2048
DUMP_IVAL = 0.00001

# DEBUGGING
#bess.set_debug(True)

# Helpers
def aton(ip):
    return socket.inet_aton(ip)
# CloudLab experiment platform specific code:
def node2id(node):
    node2id_dict = {
        'node-1.loomtest2.opennf-pg0.clemson.cloudlab.us': 1,
        'node-0.loomtest2.opennf-pg0.clemson.cloudlab.us': 2,
    }
    return node2id_dict[node]
node_name = platform.node()
node_id = node2id(node_name)
def config_rfs(iface):
    rxqs = glob.glob('/sys/class/net/%s/queues/rx-*' % iface)
    #entries = 65536
    entries = 0
    entries_per_rxq = entries / len(rxqs)
    cmd = 'echo %d | sudo tee /proc/sys/net/core/rps_sock_flow_entries > /dev/null' % \
        entries
    subprocess.check_call(cmd, shell=True)
    for rxq in rxqs:
        cmd = 'echo %d | sudo tee /%s/rps_flow_cnt > /dev/null' % (entries_per_rxq, rxq)
        subprocess.check_call(cmd, shell=True)
def start_ping_proc(ip):
    ping_cmd = 'sudo ping -i 0.001 -c 20 %s' % ip
    proc = subprocess.Popen(ping_cmd, shell=True,
        stderr=subprocess.STDOUT, stdout=subprocess.PIPE)
    return proc
def make_tcpdump_fifo(fifo):
    try:
        os.remove(fifo)
    except:
        pass
    os.mkfifo(fifo, 0o600)
    fd = os.open(fifo, os.O_RDWR)
    return fifo

class VhostConf(object):
    def __init__(self, *initial_data, **kwargs):
        for dictionary in initial_data:
            for key in dictionary:
                setattr(self, key, dictionary[key])
        for key in kwargs:
            setattr(self, key, kwargs[key])
def gen_vhost_conf():
    i = 1
    vhost_conf_dict = {
        'name': 'loom%d' % i,
        'addr': '10.10.10%d.%d' % (i, node_id),
        'extra_addrs': ['10.10.102.%d' % (node_id)],
        'mac': '00:8c:fa:00:A{}:{:02x}'.format(i, node_id),
        'netns': 'loom_test%d' % i,
        'vlan': '10%d' % i,
    }
    vhost_conf = VhostConf(vhost_conf_dict)
    vhost_conf.addr_prefix = vhost_conf.addr + '/24'
    return vhost_conf

def config_vport(vhost_conf):
    v = VPort(ifname=vhost_conf.name, ip_addrs=[vhost_conf.addr_prefix],
        num_inc_q=TX_QUEUE_COUNT, num_out_q=RX_QUEUE_COUNT)
    config_rfs(vhost_conf.name)
    ip_cmd_prefix = ''
    #ip_cmd_prefix = 'sudo ip netns exec %s ' % vhost_conf.netns
    subprocess.check_call('%s ip link set dev %s down' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set dev %s promisc on' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    subprocess.check_call('%s ip link set %s address %s' % \
        (ip_cmd_prefix, vhost_conf.name, vhost_conf.mac), shell=True)
    subprocess.check_call('%s ip link set dev %s up' % \
        (ip_cmd_prefix, vhost_conf.name), shell=True)
    for eaddr in vhost_conf.extra_addrs:
        subprocess.check_call('%s ip addr add %s/24 dev %s ' % \
            (ip_cmd_prefix, eaddr, vhost_conf.name), shell=True)
    return v

# Reset everything at the start
#XXX: Note: I doubt both of these are necessary or are even considered
# "correct"
bess.reset_all()
#bess.resume_all()
bess.pause_all()

# Try out using different workers for inc and out
#XXX: Trying out because weighted fairness is causing problems.
#bess.add_worker(0, 0, scheduler='experimental')
#bess.add_worker(1, 28, scheduler='experimental')
bess.add_worker(0, 0)
bess.add_worker(1, 28)

# Configure the scheduler
bess.add_tc('tenant_inc_rr',
            wid=0,
            policy='round_robin')
bess.add_tc('tenant_out_rl',
            wid=1,
            policy='rate_limit',
            resource='bit',
            limit={'bit': int(10e9)})
bess.add_tc('tenant_out_rr',
            parent='tenant_out_rl',
            policy='round_robin')
#bess.add_tc('tenant_out_rr',
#            wid=1,
#            policy='round_robin')

# Get config for each vhost
v1_vhost_conf = gen_vhost_conf()

# Create a vhost as an interface on the host for each tenant
v1 = config_vport(v1_vhost_conf)

# Create a PMD port (physical) with q-txq and 1-rxq
## Only use 1-rxq because the 82599 with DPDK only does 16 RSS?
## XXX: Instead just use 16 RSS RX queues?
p = PMDPort(port_id=0, num_inc_q=RX_QUEUE_COUNT, num_out_q=TX_QUEUE_COUNT,
    size_inc_q=RX_QSIZE, size_out_q=TX_QSIZE)

#TODO: If we want to use 16-wide RSS, then we could merge then together before
# going out a HashLB

for i in range(TX_QUEUE_COUNT):
    # V Inc -> P Out (TX)
    v1_qinc = QueueInc(port=v1.name, qid=i)
    q_out = QueueOut(port=p.name, qid=i)
    v1_qinc -> IPChecksum() -> L4Checksum() -> q_out
    v1_qinc.attach_task(parent='tenant_out_rr')
    
# P Inc -> HashLB
#XXX: It seems like providing RSS through HashLB leads to bad network
# throughput.
#pq_inc = QueueInc(port=p.name, qid=0)
#hashlb = HashLB(gates=range(RX_QUEUE_COUNT), mode='l4')
#pq_inc -> IPChecksum() -> L4Checksum() -> hashlb
#pq_inc.attach_task(parent='tenant_inc_rr')

for i in range(RX_QUEUE_COUNT):
    # P Inc -> V Out (RX)
    q_inc = QueueInc(port=p.name, qid=i)
    q_inc.attach_task(parent='tenant_inc_rr')
    v1_qout = QueueOut(port=v1.name, qid=i)

    q_inc -> IPChecksum() -> L4Checksum() -> v1_qout
    #hashlb:i -> v1_qout

bess.resume_all()

## Dump outgoing packets for later analysis
#out_fifo = make_tcpdump_fifo('/tmp/pout.pcap')
#bess.tcpdump(True, p_out.name, direction='in', fifo=out_fifo)
#tcpdump_cmd = 'sudo tcpdump -r /tmp/pout.pcap -s 64 -w /dev/shm/spark_tcp_flows.pcap -s 64'
#tcpdump = subprocess.Popen(shlex.split(tcpdump_cmd),
#    stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
#tcpdump.wait()
